{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description: This script\n",
    "\n",
    "Input:   data/ref_data/ARanalysis_ref_data.nc\n",
    "\n",
    "       'data/AR_features/part1/AR_feature.part1.%s.1981-2015.nc' % (method)\n",
    "\n",
    "Output: 'data/AR_features/part2/AR_feature.part2.%s.1981-2015.nc' % (method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from skimage.draw import polygon\n",
    "from skimage import measure\n",
    "from math import radians, sin, cos, acos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/raid1/chen423/serdp/archive/GRL2018/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_file = rootdir+'data/ref_data/ARanalysis_ref_data.nc'\n",
    "refgroup = nc.Dataset(ref_file, 'r', format='NETCDF4')\n",
    "ref_lats = refgroup.variables['pt_lat'][:]\n",
    "ref_lons = refgroup.variables['pt_lon'][:]\n",
    "refgroup.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grid_length(index):\n",
    "    \n",
    "    slat = radians(float((ref_lats[index]+ref_lats[index-1])/2))\n",
    "    slon = radians(float((ref_lons[index]+ref_lons[index-1])/2))\n",
    "    elat = radians(float((ref_lats[index]+ref_lats[index+1])/2))\n",
    "    elon = radians(float((ref_lons[index]+ref_lons[index+1])/2))\n",
    "    dist = 6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct reference distance\n",
    "ref_gridlen = np.zeros(ref_lats.shape)\n",
    "for i in np.arange(1,ref_gridlen.shape[0]-1):\n",
    "    ref_gridlen[i] = calc_grid_length(i)\n",
    "    \n",
    "# first point\n",
    "slat = radians(float(ref_lats[0]))\n",
    "slon = radians(float(ref_lons[0]))\n",
    "elat = radians(float((ref_lats[0]+ref_lats[1])/2))\n",
    "elon = radians(float((ref_lons[0]+ref_lons[1])/2))\n",
    "ref_gridlen[0] = (6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon)))*2\n",
    "\n",
    "# last point\n",
    "slat = radians(float(ref_lats[ref_gridlen.shape[0]-2]))\n",
    "slon = radians(float(ref_lons[ref_gridlen.shape[0]-2]))\n",
    "elat = radians(float((ref_lats[ref_gridlen.shape[0]-2]+ref_lats[ref_gridlen.shape[0]-1])/2))\n",
    "elon = radians(float((ref_lons[ref_gridlen.shape[0]-2]+ref_lons[ref_gridlen.shape[0]-1])/2))\n",
    "ref_gridlen[ref_gridlen.shape[0]-1]= (6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon)))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ARcentroid(xs, ys):\n",
    "    weights = ref_gridlen[ys]*ARint_coast[xs,ys]\n",
    "    centroid_x = ((xs*weights).sum())/(weights.sum())\n",
    "    centroid_y = ((ys*weights).sum())/(weights.sum())\n",
    "    return int(round(centroid_x)), int(round(centroid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_AR(incontour, ARint_coast):\n",
    "    xs, ys = polygon(np.round_(incontour[:,0]), np.round_(incontour[:,1]), ARint_coast.shape)\n",
    "    # sometimes the contour denotes the \"missing\" part within a larger AR contour, so get rid of these.\n",
    "    weights = ref_gridlen[ys]*ARint_coast[xs,ys]\n",
    "    if weights.sum()==0:\n",
    "        sig = False\n",
    "    else:\n",
    "        sig = True\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_2pts_distance(sindex, eindex):\n",
    "    \n",
    "    slat = radians(float(ref_lats[sindex]))\n",
    "    slon = radians(float(ref_lons[sindex]))\n",
    "    elat = radians(float(ref_lats[eindex]))\n",
    "    elon = radians(float(ref_lons[eindex]))\n",
    "    #print(\"(%.3f  %.3f), (%.3f  %.3f)\" % (ref_lats[sindex], ref_lons[sindex], ref_lats[eindex], ref_lons[eindex]))\n",
    "\n",
    "    dist = 6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_event_coastal_feature(x_sets, y_sets):\n",
    "    # x is time dimension, y is space dimension\n",
    "    \n",
    "    # mean width along the coast, and mean intensity at the coast\n",
    "    total_width = 0\n",
    "    count = 0\n",
    "    total_intensity = 0\n",
    "    total_intensity_count = 0\n",
    "    for x in np.unique(x_sets):\n",
    "        tmp_ys = y_sets[x_sets==x]\n",
    "        tmp_ymin = tmp_ys.min()\n",
    "        tmp_ymax = tmp_ys.max()\n",
    "        #print(x, tmp_ymin, tmp_ymax)\n",
    "        if tmp_ymax==tmp_ymin:\n",
    "            total_width = total_width + ref_gridlen[tmp_ymax]\n",
    "        else:\n",
    "            total_width = total_width + calc_2pts_distance(tmp_ymin, tmp_ymax)\n",
    "        for y in np.unique(tmp_ys):\n",
    "            total_intensity = total_intensity + ARint_coast[x,y] * ref_gridlen[y]\n",
    "            total_intensity_count = total_intensity_count + ref_gridlen[y]\n",
    "        count = count + 1\n",
    "    mean_width = total_width/float(count)\n",
    "    mean_intensity = total_intensity/total_intensity_count\n",
    "    \n",
    "    return mean_width, mean_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the key functions. It will correct the grids in the polygon, by removing those where coast intensity is zero. this is\n",
    "# caused by the interpolation of measure.find_contours.\n",
    "def clip_out_real_AR(inx, iny, coast_int):\n",
    "    outx = []\n",
    "    outy = []\n",
    "    for i in np.arange(inx.shape[0]):\n",
    "        if coast_int[inx[i], iny[i]]>0:\n",
    "            outx.append(inx[i])\n",
    "            outy.append(iny[i])\n",
    "    outx_array = np.asarray(outx)\n",
    "    outy_array = np.asarray(outy)\n",
    "    return outx_array, outy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ARevent_features(incontour, refdata):\n",
    "    \n",
    "    xs_raw, ys_raw = polygon(np.round_(incontour[:,0]), np.round_(incontour[:,1]), refdata.shape)\n",
    "    xs, ys = clip_out_real_AR(xs_raw, ys_raw, ARint_coast)\n",
    "    outdata = np.ones(11)*9999.0\n",
    "    \n",
    "    # following values are already weight by gridarea at every timestep. So here just take one value per timestep, then average.\n",
    "    # 1. area, full\n",
    "    tmp_total = 0\n",
    "    tmp_count = 0\n",
    "    for i in np.unique(xs):\n",
    "        tmp_total = tmp_total + ARarea_full[i,ys[xs==i][0]]\n",
    "        tmp_count = tmp_count + 1\n",
    "    outdata[0] = tmp_total/float(tmp_count)\n",
    "    \n",
    "    # 2. area, land\n",
    "    tmp_total = 0\n",
    "    tmp_count = 0\n",
    "    for i in np.unique(xs):\n",
    "        tmp_total = tmp_total + ARarea_land[i,ys[xs==i][0]]\n",
    "        tmp_count = tmp_count + 1\n",
    "    outdata[1] = tmp_total/float(tmp_count)\n",
    "    \n",
    "    # 3. intensity, full area\n",
    "    tmp_total = 0\n",
    "    tmp_count = 0\n",
    "    for i in np.unique(xs):\n",
    "        tmp_total = tmp_total + ARint_full[i,ys[xs==i][0]]*ARarea_full[i,ys[xs==i][0]]\n",
    "        tmp_count = tmp_count + ARarea_full[i,ys[xs==i][0]]\n",
    "    outdata[2] = tmp_total/float(tmp_count)\n",
    "    \n",
    "    # 4. intensity, land\n",
    "    tmp_total = 0\n",
    "    tmp_count = 0\n",
    "    for i in np.unique(xs):\n",
    "        tmp_total = tmp_total + ARint_land[i,ys[xs==i][0]]*ARarea_land[i,ys[xs==i][0]]\n",
    "        tmp_count = tmp_count + ARarea_land[i,ys[xs==i][0]]\n",
    "    outdata[3] = tmp_total/float(tmp_count)\n",
    "    \n",
    "    # 5. coastal features\n",
    "    # coastal width;  coastal intensity\n",
    "    outdata[4], outdata[5] = compute_event_coastal_feature(xs, ys)    \n",
    "    \n",
    "    # 6. centroid\n",
    "    centroid_x, centroid_y = calc_ARcentroid(xs, ys)\n",
    "    outdata[6] = xs.min()  # start timestep\n",
    "    outdata[7] = (xs.max()-xs.min()+1)*3   # duration, in hours\n",
    "    # find centroid time and location\n",
    "    outdata[8] = centroid_x  # center timestep\n",
    "    outdata[9] = ref_lats[centroid_y]  # center lat\n",
    "    outdata[10] = ref_lons[centroid_y]  # center lon\n",
    "\n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nc_results(method, outdata):\n",
    "    \n",
    "    outfile = rootdir+'data/AR_features/part2/%s.AR_events_feature.1981-2015.nc' % (method)\n",
    "    outgroup = nc.Dataset(outfile, 'w', format='NETCDF4')\n",
    "\n",
    "    # dimension\n",
    "    edim = outgroup.createDimension('event', outdata.shape[0])\n",
    "    vdim = outgroup.createDimension('feature', 11)\n",
    "\n",
    "    # vars\n",
    "    evar = outgroup.createVariable('event', 'i4', ('event'))\n",
    "    evar.long_name = 'AR events reaching US west coast'\n",
    "    vvar = outgroup.createVariable('feature', 'i4', ('feature'))\n",
    "    vvar.long_name = 'AR features'\n",
    "    evar[:] = np.arange(outdata.shape[0])\n",
    "    vvar[:] = np.arange(11)\n",
    "\n",
    "    featurevar = outgroup.createVariable('AR_event_feature', 'f4', ('event','feature'))\n",
    "    featurevar[:] = outdata\n",
    "    featurevar.feature0 = 'mean size of whole AR region. Only counting those times where AR intersects with coast/land'\n",
    "    featurevar.feature0unit = 'km^2'\n",
    "    featurevar.feature1 = 'mean size of AR region over land'\n",
    "    featurevar.feature1unit = 'km^2'\n",
    "    featurevar.feature2 = 'mean intensity of whole AR'\n",
    "    featurevar.feature2unit = 'kg/m/s'\n",
    "    featurevar.feature3 = 'mean intensity of land AR'\n",
    "    featurevar.feature3unit = 'kg/m/s'\n",
    "    featurevar.feature4 = 'coastal width of AR'\n",
    "    featurevar.feature4unit = 'km'\n",
    "    featurevar.feature5 = 'coastal mean intensity of AR'\n",
    "    featurevar.feature5unit = 'kg/m/s'\n",
    "    featurevar.feature6 = 'start timesetp of AR'\n",
    "    featurevar.feature6unit = 'index. Step 0 is 1981-01-01_00, deltatime is 3 hours'\n",
    "    featurevar.feature7 = 'duration of AR. Only counting those time when AR intersects with coast/land'\n",
    "    featurevar.feature7unit = 'hours'\n",
    "    featurevar.feature8 = 'AR center timestep'\n",
    "    featurevar.feature8unit = 'index. Step 0 is 1981-01-01_00, deltatime is 3 hours'\n",
    "    featurevar.feature9 = 'AR center latitude'\n",
    "    featurevar.feature9unit = 'degrees_north'\n",
    "    featurevar.feature10 = 'AR center longitude'\n",
    "    featurevar.feature10unit = 'degrees_east'\n",
    "\n",
    "    outgroup.script = '/usr1/chen423/serdp/tools/ipython/paper1_experiments/Regression_with_AR/Step2_collect_ARfeature.part2_events.ipynb'\n",
    "\n",
    "    outgroup.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main function\n",
    "\n",
    "for 5 methods. For \"rutz\", see the followig block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-92a71352c555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mARint_coast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ARint_coast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mARarea_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ARarea_full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mARarea_land\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ARarea_land'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mingroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._toma\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#method = 'gershunov'\n",
    "#method = 'goldenson'\n",
    "#method = 'guan'\n",
    "#method = 'pnnl1'\n",
    "#method = 'pnnl2'\n",
    "\n",
    "#method = 'lora'\n",
    "#method = 'payne'\n",
    "method = 'shields'\n",
    "#method = 'tempest'\n",
    "#method = 'walton'\n",
    "\n",
    "infile = rootdir+'data/AR_features/part1/AR_feature.part1.%s.1981-2015.nc' % (method)\n",
    "ingroup = nc.Dataset(infile, 'r', format='NETCDF4')\n",
    "ARint_full = ingroup.variables['ARint_full'][:]\n",
    "ARint_land = ingroup.variables['ARint_land'][:]\n",
    "ARint_coast = ingroup.variables['ARint_coast'][:]\n",
    "ARarea_full = ingroup.variables['ARarea_full'][:]\n",
    "ARarea_land = ingroup.variables['ARarea_land'][:]\n",
    "ingroup.close()\n",
    "    \n",
    "refdata = ARint_coast.copy()\n",
    "refdata[ARint_coast>0] = 1\n",
    "contours = measure.find_contours(refdata, 0.9)\n",
    "    \n",
    "    \n",
    "nevents_fake = len(contours)\n",
    "AR_TF = np.zeros(nevents_fake)\n",
    "for i in np.arange(nevents_fake):\n",
    "    sig = verify_AR(contours[i], ARint_coast)\n",
    "    if sig==True:\n",
    "        AR_TF[i] = 1\n",
    "\n",
    "nevents = (AR_TF==1).sum()\n",
    "print(nevents_fake, nevents)\n",
    "    \n",
    "outdata_full = np.ones((nevents,11))*9999.0\n",
    "count = 0\n",
    "for i in np.arange(nevents_fake):\n",
    "    if AR_TF[i]==1:\n",
    "        outdata_full[count,:] = compute_ARevent_features(contours[i], refdata)\n",
    "        count = count + 1\n",
    "            \n",
    "#save_nc_results(method, outdata_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the codes below are for rutz only.\n",
    "\n",
    "There are some events whose main region is in the very south of 25-30 band, so the AR intesity at coast are pretty low (i.e., <100kg/m/s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12014 7328\n"
     ]
    }
   ],
   "source": [
    "method = 'rutz'\n",
    "\n",
    "infile = rootdir+'data/AR_features/part1/AR_feature.part1.%s.1981-2015.nc' % (method)\n",
    "ingroup = nc.Dataset(infile, 'r', format='NETCDF4')\n",
    "ARint_full = ingroup.variables['ARint_full'][:]\n",
    "ARint_land = ingroup.variables['ARint_land'][:]\n",
    "ARint_coast = ingroup.variables['ARint_coast'][:]\n",
    "ARarea_full = ingroup.variables['ARarea_full'][:]\n",
    "ARarea_land = ingroup.variables['ARarea_land'][:]\n",
    "ingroup.close()\n",
    "    \n",
    "refdata = ARint_coast.copy()\n",
    "refdata[ARint_coast>0] = 1\n",
    "contours = measure.find_contours(refdata, 0.9)\n",
    "    \n",
    "    \n",
    "nevents_fake = len(contours)\n",
    "AR_TF = np.zeros(nevents_fake)\n",
    "for i in np.arange(nevents_fake):\n",
    "    sig = verify_AR(contours[i], ARint_coast)\n",
    "    if sig==True:\n",
    "        AR_TF[i] = 1\n",
    "\n",
    "nevents = (AR_TF==1).sum()\n",
    "print(nevents_fake, nevents)\n",
    "    \n",
    "outdata_full = np.ones((nevents,11))*9999.0\n",
    "count = 0\n",
    "for i in np.arange(nevents_fake):\n",
    "    if AR_TF[i]==1:\n",
    "        outdata_full[count,:] = compute_ARevent_features(contours[i], refdata)\n",
    "        count = count + 1\n",
    "\n",
    "# remove the strange events\n",
    "test_data = outdata_full[:,5]\n",
    "events_use = (test_data>200).sum()\n",
    "outdata_full_clip = np.zeros((events_use, 11))\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(test_data.shape[0]):\n",
    "    if outdata_full[i,5]>200:\n",
    "        outdata_full_clip[count,:] = outdata_full[i,:]\n",
    "        count = count + 1\n",
    "    \n",
    "#save_nc_results(method, outdata_full_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7328, 11) 7324\n"
     ]
    }
   ],
   "source": [
    "print(outdata_full.shape, events_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_event_to_orig(inevent):\n",
    "    count = 0\n",
    "    for i in np.arange(AR_TF.shape[0]):\n",
    "        if AR_TF[i]==1:\n",
    "            count = count + 1\n",
    "            if count==inevent+1:\n",
    "                print('%d -> %d' % (count-1, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_results(indata):\n",
    "    print('AR area:                %.3f km^2' % (indata[0]))\n",
    "    print('AR area (land):         %.3f km^2' % (indata[1]))\n",
    "    print('AR intensity:           %.3f kg/m/s' % (indata[2]))\n",
    "    print('AR intensity (land):    %.3f kg/m/s' % (indata[3]))\n",
    "    print('AR width (coastal):     %.3f km' % (indata[4]))\n",
    "    print('AR intensity (coastal): %.3f kg/m/s' % (indata[5]))\n",
    "    print('start time:             %d index' % (indata[6]))\n",
    "    print('duration:               %d hours' % (indata[7]))\n",
    "    print('center time:            %d index' % indata[8])\n",
    "    print('center lat:             %.3f deg' % (indata[9]))\n",
    "    print('center lon:             %.3f deg' % (indata[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(outdata_full[:,7]==234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
